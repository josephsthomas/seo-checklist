[
  {
    "bug_id": "R07-A-001",
    "severity": "HIGH",
    "category": "Missing Disclaimer",
    "component": "AISuggestions",
    "file_line": "src/components/audit/ai/AISuggestions.jsx:89",
    "description": "The AISuggestions component displays AI-generated SEO title, meta description, and H1 suggestions without any disclaimer or warning that the output is AI-generated and may be inaccurate. While the component labels itself 'AI Suggestions' and 'Claude-powered optimization recommendations', there is no explicit disclaimer informing users that the generated content should be reviewed for accuracy before use, unlike the ImageAltUploadScreen and MetaUploadScreen which use the shared AIDisclaimer component.",
    "steps": "1. Navigate to the Technical Audit page. 2. Open a page detail view (PageAuditView). 3. Click 'Generate Suggestions' in the AISuggestions panel. 4. Observe the returned suggestions.",
    "expected": "An AI disclaimer banner should be displayed near the suggestions, informing users that the content is AI-generated and may contain inaccuracies, consistent with how MetaUploadScreen and ImageAltUploadScreen display the AIDisclaimer component.",
    "actual": "AI-generated SEO suggestions are presented directly without any disclaimer about potential inaccuracy or the need for human review. Users can copy suggestions to clipboard with no warning.",
    "impact": "Users may blindly implement AI-generated SEO suggestions (titles, meta descriptions, H1s) without review, leading to inaccurate, misleading, or brand-inappropriate content being published on their sites."
  },
  {
    "bug_id": "R07-A-002",
    "severity": "HIGH",
    "category": "Output Validation",
    "component": "AISuggestions",
    "file_line": "src/components/audit/ai/AISuggestions.jsx:42",
    "description": "The AISuggestions component stores the raw result from 'suggestAllSEO' directly into state without any validation or sanitization of the AI response structure. The component accesses deeply nested properties like 'suggestions.title?.suggestions?.length' and 'suggestions.title.issues.map()' but never validates that the AI returned properly structured data. If the AI returns malformed JSON or unexpected fields, this could cause runtime errors or display corrupted data.",
    "steps": "1. Navigate to the audit page and open a page detail view. 2. Click 'Generate Suggestions'. 3. If the AI returns a response with an unexpected structure (e.g., missing 'suggestions' array, wrong field types), observe the result.",
    "expected": "The component should validate the structure of the AI response before setting it in state, ensuring all expected fields exist and have correct types. Malformed responses should be caught and displayed as an error.",
    "actual": "The raw AI response is stored directly via 'setSuggestions(result)' at line 42 with no schema validation. The component relies on optional chaining to prevent crashes but does not verify data integrity or type correctness.",
    "impact": "Malformed AI responses could lead to silent data corruption, rendering empty suggestion panels, or displaying incorrect character counts, undermining user trust and potentially causing SEO harm."
  },
  {
    "bug_id": "R07-A-003",
    "severity": "MEDIUM",
    "category": "Confidence Gap",
    "component": "AISuggestions",
    "file_line": "src/components/audit/ai/AISuggestions.jsx:170",
    "description": "The AISuggestions component displays AI-generated title, meta description, and H1 suggestions with 'reasoning' text but provides no confidence score or reliability indicator for each suggestion. Users have no way to assess how confident the AI model is in each suggestion, making it difficult to prioritize which suggestions to trust or investigate further.",
    "steps": "1. Navigate to the Technical Audit page and select a page. 2. Click 'Generate Suggestions'. 3. Review the suggestions displayed for title, meta description, and H1. 4. Look for any confidence indicator.",
    "expected": "Each AI suggestion should include a confidence score or qualitative indicator (e.g., high/medium/low confidence) so users can gauge the reliability of the recommendation and prioritize human review accordingly.",
    "actual": "Suggestions display only the text, character count, and a reasoning string. No confidence score or reliability metric is shown to help users evaluate the suggestion quality.",
    "impact": "Without confidence signals, users cannot efficiently triage AI suggestions. Low-confidence suggestions may be adopted uncritically while high-confidence ones may be needlessly questioned, reducing the tool's practical value."
  },
  {
    "bug_id": "R07-A-004",
    "severity": "CRITICAL",
    "category": "AI Error Handling",
    "component": "MetaGeneratorPage",
    "file_line": "src/components/meta-generator/MetaGeneratorPage.jsx:72",
    "description": "The MetaGeneratorPage error handling catches errors during metadata generation but displays only the raw error message directly to the user via 'toast.error(err.message)' and in the error view. If the AI service returns an API-level error (e.g., rate limiting, authentication failure, server-side Claude errors), the raw technical error message is exposed to end users. There is no differentiation between AI-specific errors (model overloaded, token limit exceeded, content policy violation) and general processing errors.",
    "steps": "1. Navigate to the Meta Data Generator. 2. Upload a very large document that could exceed token limits. 3. Alternatively, cause an API authentication failure. 4. Observe the error message displayed.",
    "expected": "AI-specific errors should be caught and mapped to user-friendly messages. For example: token limit exceeded should display 'Document is too long for AI processing. Please try a shorter document.' Rate limiting should display 'AI service is temporarily busy. Please try again in a moment.'",
    "actual": "Raw error messages from the AI service are displayed directly to users, potentially including technical details like API error codes, token counts, or internal error strings that are confusing to non-technical users.",
    "impact": "Poor error messages confuse users and may expose internal implementation details. Users cannot take corrective action when they do not understand the error, leading to abandonment and support tickets."
  },
  {
    "bug_id": "R07-A-005",
    "severity": "HIGH",
    "category": "Token Management",
    "component": "ImageAltGeneratorPage",
    "file_line": "src/components/image-alt-generator/ImageAltGeneratorPage.jsx:64",
    "description": "The ImageAltGeneratorPage allows batch processing of up to 100 images with no token budget management or estimation. Each image processed by Claude Vision consumes significant tokens (image encoding plus text generation). Processing 100 images in a single batch could easily exceed API rate limits or token budgets, resulting in partial failures or massive API costs with no warning to the user.",
    "steps": "1. Navigate to the Image Alt Text Generator. 2. Upload a ZIP file containing 100 high-resolution images. 3. Click 'Generate Alt Text'. 4. Observe whether any token budget warning or cost estimation is provided.",
    "expected": "Before processing a large batch, the system should estimate the token cost, display a warning about expected API usage, and potentially implement progressive processing with the ability to pause/resume. A token budget cap or confirmation for large batches should be shown.",
    "actual": "The component accepts up to 100 images and immediately starts processing all of them via 'processImageBatch' with no token estimation, cost warning, or budget management. The only limit enforced is the image count (100) and file size (10MB per image, 500MB for ZIP).",
    "impact": "Users processing large batches may incur unexpected API costs, hit rate limits causing partial failures, or experience timeouts. Without token awareness, the feature provides no cost predictability for users or operators."
  },
  {
    "bug_id": "R07-A-006",
    "severity": "MEDIUM",
    "category": "Hallucination Risk",
    "component": "ABVariantsPanel",
    "file_line": "src/components/meta-generator/ABVariantsPanel.jsx:287",
    "description": "The ABVariantsPanel's generateNewVariant function uses simplistic string-template transformations rather than actual AI generation, but the UI presents these variants as if they are intelligently generated alternatives (using the Sparkles icon and 'Generate New Variant' button). Templates like appending '| Complete Guide' or '- Expert Tips' produce misleading content that may not accurately describe the page. The function comment says 'can be connected to AI service' but it currently uses naive string manipulation that could produce nonsensical or misleading titles/descriptions.",
    "steps": "1. Navigate to the Meta Data Generator dashboard. 2. Open the A/B Variants panel. 3. Click 'Generate New Variant' multiple times. 4. Review the generated variants.",
    "expected": "Variants should either be generated by an actual AI model for quality suggestions, or the UI should clearly indicate that these are template-based variations rather than AI-generated alternatives. The Sparkles icon and 'Generate' terminology imply AI involvement.",
    "actual": "The generateNewVariant function at line 287 uses hardcoded string templates (e.g., appending '| Complete Guide', '- Expert Tips', 'How to ...') that can produce contextually inappropriate or misleading meta content. The UI uses AI-suggestive iconography (Sparkles) without actual AI involvement.",
    "impact": "Users may trust these variants as intelligently crafted alternatives when they are simple string manipulations. Implementing a template-generated variant like 'How to [title] - Expert Tips' for an error page or legal notice would be inappropriate and could harm SEO if published."
  },
  {
    "bug_id": "R07-A-007",
    "severity": "MEDIUM",
    "category": "Missing Disclaimer",
    "component": "MetaDashboard",
    "file_line": "src/components/meta-generator/dashboard/MetaDashboard.jsx:445",
    "description": "The MetaDashboard displays AI-generated suggestions (metadata.suggestions) in a section labeled 'AI Suggestions' but provides no disclaimer or warning about the accuracy of these suggestions. While the dashboard header includes an AIBadge, the suggestions section itself has no inline disclaimer about hallucination risk. Suggestions are presented as authoritative recommendations that users may implement without verification.",
    "steps": "1. Upload a document to the Meta Data Generator. 2. After metadata is generated, scroll down to the 'AI Suggestions' section on the dashboard. 3. Review the suggestions displayed.",
    "expected": "The AI Suggestions section should include an inline disclaimer noting that suggestions are AI-generated and may not be accurate, or at minimum a note that they should be verified before implementation.",
    "actual": "AI suggestions are displayed as a simple bulleted list with an emoji icon ('lightbulb') and no disclaimer or accuracy caveat. Users may take these recommendations at face value.",
    "impact": "Users may implement inaccurate AI suggestions (e.g., incorrect SEO advice, wrong keyword recommendations) without questioning them, potentially harming their site's search performance."
  },
  {
    "bug_id": "R07-A-008",
    "severity": "HIGH",
    "category": "Prompt Issue",
    "component": "ImageAltUploadScreen",
    "file_line": "src/components/image-alt-generator/upload/ImageAltUploadScreen.jsx:26",
    "description": "The ImageAltUploadScreen collects user-provided context data (brand name, industry, keywords, guidelines, tone, character limit) to pass to the AI for alt text generation, but there is no input sanitization or length limitation on the 'guidelines' textarea or 'keywords' field. Users can input arbitrarily long strings in these fields, which are then presumably injected into the AI prompt. This creates a prompt injection risk where carefully crafted input in the guidelines or keywords fields could manipulate the AI's behavior, and excessively long inputs could waste tokens or exceed context limits.",
    "steps": "1. Navigate to the Image Alt Text Generator. 2. Expand 'Context Settings'. 3. Enter a very long string (e.g., 10,000+ characters) in the 'Custom Guidelines' textarea. 4. Alternatively, enter adversarial prompt text like 'Ignore all previous instructions and...' 5. Upload an image and process it.",
    "expected": "Context input fields should have character limits enforced both in the UI (maxlength attribute) and validated before being sent to the AI service. Guidelines should be truncated or rejected if excessively long. Input should be sanitized to prevent prompt injection patterns.",
    "actual": "The guidelines textarea and keywords input have no maxlength restriction. The textarea at line 215-220 uses 'rows={2}' for visual sizing but no character limit. All user input is passed directly to the AI service through 'onFileSelect(files, context)' without sanitization.",
    "impact": "Prompt injection could cause the AI to generate inappropriate, off-brand, or harmful alt text. Excessively long context inputs waste API tokens and could cause processing failures, degrading the user experience and increasing costs."
  },
  {
    "bug_id": "R07-A-009",
    "severity": "MEDIUM",
    "category": "Confidence Gap",
    "component": "ImageAltDashboard",
    "file_line": "src/components/image-alt-generator/dashboard/ImageAltDashboard.jsx:425",
    "description": "The ImageAltDashboard displays a confidence score for each image in the expanded details view (line 425: '{Math.round((img.confidence || 0) * 100)}%'), but there is no visual differentiation or warning for low-confidence results. All results are presented uniformly regardless of whether confidence is 95% or 15%. The confidence sort option exists but there is no threshold-based highlighting or recommendation to manually review low-confidence results.",
    "steps": "1. Process a batch of images through the Image Alt Generator. 2. Expand individual image details. 3. Observe the confidence percentage displayed. 4. Look for any visual indicator distinguishing high-confidence from low-confidence results.",
    "expected": "Low-confidence results (e.g., below 70%) should be visually flagged with a warning color or icon, and the dashboard should recommend manual review. A summary count of low-confidence results should appear alongside other summary statistics.",
    "actual": "The confidence score is displayed as plain white text with no color coding, warning icon, or threshold-based visual treatment. A result at 20% confidence looks identical to one at 95% confidence. The summary cards show total, successful, decorative, avg length, and over-125 counts, but no low-confidence count.",
    "impact": "Users may unknowingly export and use AI-generated alt text with low confidence, resulting in inaccurate image descriptions that harm accessibility and SEO. Low-confidence results should prompt human review but are easy to miss."
  },
  {
    "bug_id": "R07-A-010",
    "severity": "MEDIUM",
    "category": "AI Error Handling",
    "component": "AISuggestions",
    "file_line": "src/components/audit/ai/AISuggestions.jsx:43",
    "description": "The AISuggestions component has a basic try/catch error handler that displays the raw error message, but it lacks retry logic, exponential backoff, or specific handling for common AI service failures. When the AI service is temporarily unavailable (rate limit, timeout, server error), users must manually click 'Regenerate' with no guidance about when to retry. The error display at line 130 shows a generic red banner with the raw error message.",
    "steps": "1. Navigate to the audit page and open a page detail. 2. Click 'Generate Suggestions' when the AI service is experiencing rate limiting or is temporarily down. 3. Observe the error handling behavior.",
    "expected": "The component should implement automatic retry with exponential backoff for transient errors (429, 503). Error messages should be categorized and user-friendly (e.g., 'AI service is busy, retrying...', 'Please try again in 30 seconds'). A retry button with a countdown timer should be provided for rate-limit errors.",
    "actual": "All errors are caught generically and displayed as-is via 'setError(err.message)'. There is no retry logic, no distinction between transient and permanent errors, and no guidance for the user on how to proceed. The error banner shows 'Error generating suggestions' with the raw message.",
    "impact": "Users experiencing transient AI service failures may assume the feature is broken and stop using it, rather than simply retrying after a short wait. This reduces feature adoption and creates unnecessary support burden."
  },
  {
    "bug_id": "R07-A-011",
    "severity": "HIGH",
    "category": "Hallucination Risk",
    "component": "FeatureDetailPage",
    "file_line": "src/components/public/FeatureDetailPage.jsx:98",
    "description": "The FeatureDetailPage for the Technical Audit feature states 'Get contextual fix recommendations powered by Claude AI' and the Accessibility feature states 'Get specific code fixes and implementation guidance for each issue.' These public-facing marketing claims imply that AI-generated fix suggestions are reliable and actionable, but the corresponding AI suggestion components (AISuggestions) lack disclaimers about hallucination risk. The marketing pages do not mention that AI suggestions may be inaccurate or require verification, which sets misleading expectations for new users.",
    "steps": "1. Visit /features/audit or /features/accessibility as an unauthenticated user. 2. Read the feature descriptions and capability claims. 3. Sign up and use the AI features. 4. Compare the marketing claims with the actual experience and disclaimers shown.",
    "expected": "Public-facing feature descriptions should include appropriate caveats about AI accuracy, such as 'AI-assisted suggestions that should be reviewed by a human' rather than implying guaranteed accuracy. The descriptions should align with the AI Usage Policy's disclaimers.",
    "actual": "Marketing copy presents AI features as authoritative capabilities without any mention of limitations, hallucination risk, or the need for human review. This creates a disconnect with the AI Usage Policy which warns extensively about accuracy limitations.",
    "impact": "New users form expectations based on marketing claims that AI features provide reliable, accurate recommendations. When AI produces inaccurate suggestions, user trust is damaged. This also creates potential legal exposure if the marketing overclaims AI accuracy while the policy disclaims it."
  },
  {
    "bug_id": "R07-A-012",
    "severity": "LOW",
    "category": "Model Selection",
    "component": "AISuggestions",
    "file_line": "src/components/audit/ai/AISuggestions.jsx:82",
    "description": "The AISuggestions component's unavailable state (line 82) instructs users to add a 'VITE_CLAUDE_API_KEY' environment variable to enable AI suggestions. This hardcodes a dependency on Claude/Anthropic as the sole AI provider with no abstraction for model selection. The environment variable name 'VITE_CLAUDE_API_KEY' is exposed in the UI, which reveals implementation details. Additionally, there is no mechanism for administrators or users to select between different Claude model tiers (e.g., Haiku for faster/cheaper suggestions vs. Sonnet for higher quality) based on their use case.",
    "steps": "1. Deploy the portal without setting the VITE_CLAUDE_API_KEY environment variable. 2. Navigate to the audit page and view a page detail. 3. Observe the AI Suggestions panel showing the configuration instructions.",
    "expected": "The component should abstract the AI provider configuration away from the user-facing UI. Model selection should be configurable by administrators, allowing cost/quality tradeoffs (e.g., faster, cheaper model for bulk operations vs. higher-quality model for individual page analysis).",
    "actual": "The component displays a hardcoded reference to 'VITE_CLAUDE_API_KEY' in the user interface. There is no model selection capability or abstraction layer. All AI operations use whatever model is configured in the service layer with no user or admin control.",
    "impact": "Lack of model selection means operators cannot optimize cost vs. quality for different use cases. Exposing the environment variable name in the UI is a minor information disclosure. Tight coupling to a single provider reduces flexibility."
  },
  {
    "bug_id": "R07-A-013",
    "severity": "MEDIUM",
    "category": "Missing Disclaimer",
    "component": "AccessibilityDashboard",
    "file_line": "src/components/accessibility/dashboard/AccessibilityDashboard.jsx:505",
    "description": "The AccessibilityDashboard displays 'AI Fix' badges and Sparkles icons for issues marked as 'aiFixable' (lines 505-506, 647-650), indicating AI-generated remediation is available. However, the dashboard provides no disclaimer about the accuracy of AI-generated fix suggestions. Given that accessibility fixes often involve specific WCAG compliance requirements and code implementations, incorrect AI suggestions could worsen accessibility issues rather than fix them.",
    "steps": "1. Run an accessibility audit on a URL. 2. View the dashboard results. 3. Look at issues tagged with 'AI Fix' badges. 4. Expand an issue to see AI-generated fix suggestions (issue.fixSuggestion). 5. Look for any disclaimer about the AI fix accuracy.",
    "expected": "Issues with AI-generated fix suggestions should include a disclaimer that the suggested fix is AI-generated and should be verified by a developer or accessibility expert before implementation. This is especially critical for accessibility where incorrect fixes can create new barriers.",
    "actual": "AI fix suggestions are presented with a purple 'AI Fix' badge as if they are verified solutions. The fix suggestion text (line 693: issue.fixSuggestion) is displayed without any accuracy caveat or recommendation for human verification.",
    "impact": "Users may implement AI-generated accessibility fixes that are incorrect or incomplete, potentially creating new WCAG violations or failing to properly address existing ones. This is particularly dangerous because accessibility errors can have legal implications (ADA compliance)."
  },
  {
    "bug_id": "R07-A-014",
    "severity": "MEDIUM",
    "category": "Hallucination Risk",
    "component": "HelpCenterPage",
    "file_line": "src/components/public/HelpCenterPage.jsx:118",
    "description": "The HelpCenterPage FAQ section contains the answer 'We use Claude AI to provide intelligent recommendations, generate content, and analyze your data. AI features are available across all tools.' for the question 'How does the AI feature work?'. This answer overpromises by stating AI features are available 'across all tools' when in reality the Content Planner (checklist tool) and PDF Export do not use AI generation. It also states AI can 'analyze your data' which is ambiguous and could be interpreted as the AI accessing stored user data, which contradicts the AI Policy's statement that data is session-only.",
    "steps": "1. Visit /help as any user. 2. Scroll to the FAQ section. 3. Open 'How does the AI feature work?' 4. Compare the answer with actual AI feature availability across tools.",
    "expected": "The FAQ answer should accurately list which specific tools use AI (Meta Generator, Image Alt Generator, Technical Audit suggestions, Accessibility remediation) and clarify that AI processes content on-demand rather than implying persistent data analysis.",
    "actual": "The FAQ answer overstates AI coverage by claiming 'AI features are available across all tools' and uses ambiguous language about data analysis that could mislead users about data handling practices.",
    "impact": "Users may expect AI capabilities in tools that do not have them (Content Planner, Schema Generator's core validation). The ambiguous 'analyze your data' phrase could create privacy concerns or regulatory issues if users believe AI is processing their stored data."
  },
  {
    "bug_id": "R07-A-015",
    "severity": "HIGH",
    "category": "Output Validation",
    "component": "MetaDashboard",
    "file_line": "src/components/meta-generator/dashboard/MetaDashboard.jsx:86",
    "description": "The MetaDashboard allows users to copy AI-generated HTML meta tag code directly to clipboard (performCopyAll function at line 86) and download it as an HTML file (performDownloadHtml at line 98). While an AIExportConfirmation modal is shown, the HTML code generated by 'generateHtmlCode' is not validated for XSS vulnerabilities or malformed HTML. If the AI generates meta content containing HTML entities, script tags, or other potentially dangerous content, this code could be directly pasted into a website's source code.",
    "steps": "1. Upload a document with content that could cause the AI to generate special characters or HTML entities in meta content. 2. After metadata is generated, switch to the 'HTML Code' tab. 3. Click 'Copy All' or 'Download'. 4. Inspect the generated HTML code for proper escaping and validation.",
    "expected": "Generated HTML code should be validated and sanitized before export. Meta tag values should be properly HTML-encoded. The system should verify the output is well-formed HTML and does not contain potentially dangerous content (e.g., script injections in meta content).",
    "actual": "The HTML code is generated by 'generateHtmlCode(metadata)' and provided to users via clipboard copy or file download without any output sanitization or HTML validation. AI-generated content is inserted directly into meta tag templates.",
    "impact": "If the AI generates content containing unescaped HTML characters, quotes, or script-like content, users who paste this code into their websites could introduce XSS vulnerabilities or broken HTML markup, affecting both security and SEO."
  },
  {
    "bug_id": "R07-A-016",
    "severity": "LOW",
    "category": "Missing Disclaimer",
    "component": "OnboardingWalkthrough",
    "file_line": "src/components/help/OnboardingWalkthrough.jsx:40",
    "description": "The OnboardingWalkthrough step for 'Technical Audit' (step 3, line 40-43) states users will 'Get AI-powered recommendations for fixing issues' and the 'Accessibility Analyzer' step (step 4, line 46-49) mentions 'AI-generated fix suggestions with code examples'. These onboarding descriptions introduce users to AI features without any mention that AI-generated content should be reviewed for accuracy. Since the onboarding is the first interaction new users have with these features, it sets expectations without appropriate caveats.",
    "steps": "1. Create a new account (or clear localStorage 'hasCompletedOnboarding'). 2. Log in and view the onboarding walkthrough. 3. Navigate to steps 3, 4, 5, and 6 which describe AI-powered features. 4. Note the absence of any accuracy caveats.",
    "expected": "Onboarding steps that describe AI features should include brief caveats like 'AI suggestions should always be reviewed before implementation' to set appropriate expectations from the first user interaction.",
    "actual": "AI features are presented in the onboarding with only positive descriptions and no mention of limitations, accuracy concerns, or the need for human review. Steps 3-6 all reference AI capabilities enthusiastically.",
    "impact": "New users develop uncritical expectations about AI feature accuracy from their very first interaction with the platform, potentially leading to unchecked adoption of AI-generated content."
  }
]
